package config;


import javax.annotation.Resource;
import javax.sql.DataSource;

import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.batch.core.explore.JobExplorer;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.batch.item.file.FlatFileItemReader;
import org.springframework.batch.item.file.LineMapper;
import org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper;
import org.springframework.batch.item.file.mapping.DefaultLineMapper;
import org.springframework.batch.item.file.transform.DelimitedLineTokenizer;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;

import Model.User;

@Configuration
@EnableBatchProcessing(modular = true)
public class springBatchConfigrtion {
	
	
	 @Autowired
	    private ApplicationContext applicationContext;

	    @Autowired
	    private DataSource dataSource;

	    @Autowired
	    private Environment env;

	    @Autowired
	    private JobExplorer jobExplorer;

	    @Autowired
	    private JobRepository jobRepository;

	@Bean
	public Job job(JobBuilderFactory jobBulderFactory,
			StepBuilderFactory stepBuilderFactory,
			ItemReader<User> itemReader,
			ItemProcessor<User, User> itemProcessor,
			ItemWriter<User> itemWriter) {
		
		Step step = stepBuilderFactory.get("ETL-file-Lode")
				.<User,User>chunk(100)
				.reader(itemReader)
				.processor(itemProcessor)
				.writer(itemWriter)
				.build();
		Job job = jobBulderFactory.get("ETL-Load")  //we can give what we want us name
	                      .incrementer(new RunIdIncrementer())
	                      .start(step) // if i have more step i can do flow(step) .next(step)
	                      .build();
		return job;
	}
	
	@Bean
	public FlatFileItemReader<User> itemReader(@Value("${input}") Resource resource){
		
		FlatFileItemReader<User> flatFileItemReader = new FlatFileItemReader<>();
		//flatFileItemReader.setResource((org.springframework.core.io.Resource) resource);
		flatFileItemReader.setName("CSV-Reader");
		flatFileItemReader.setLinesToSkip(1);
		flatFileItemReader.setLineMapper(lineMapper());
		
		return flatFileItemReader;
	}
    
	@Bean
	public LineMapper<User> lineMapper() {
	  
		DefaultLineMapper<User> defaultLineMapper = new DefaultLineMapper<>();
		DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();
		
		lineTokenizer.setDelimiter(",");
		lineTokenizer.setStrict(false);
		lineTokenizer.setNames(new String[] {"id","name","dept","salary"});
		
		BeanWrapperFieldSetMapper<User> fileSetMaper = new BeanWrapperFieldSetMapper<>();
		fileSetMaper.setTargetType(User.class);
 		defaultLineMapper.setLineTokenizer(lineTokenizer);
 		defaultLineMapper.setFieldSetMapper(fileSetMaper);
		return defaultLineMapper;
	}
	
	
}
